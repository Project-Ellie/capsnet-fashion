{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import dataset\n",
    "# from models.conv2_dense2_dropout import Model\n",
    "from models.dense3 import Model\n",
    "\n",
    "from helpers.os_utils import os_info\n",
    "from helpers.history import ExpHistory\n",
    "#from helpers.gpu_utils import validate_batch_size_for_multi_gpu\n",
    "from helpers.softmax_cross_entropy_trainer import create_model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the history and the runtime context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Welcome, wgiersche, it's Tue May  1 12:53:25 2018, and you'll be working with Tensorflow version 1.8.0\n",
      "Your current runtime: \n",
      "  node: scylla, \n",
      "  os: Linux-4.13.0-39-generic-x86_64-with-Ubuntu-16.04-xenial, \n",
      "  machine: x86_64, \n",
      "  cuda: True\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>cuda</th>\n",
       "      <th>multi_gpu</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_epochs</th>\n",
       "      <th>localtime</th>\n",
       "      <th>steps</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon Apr 30 17:28:43 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MacPro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 06:36:35 2018</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PC-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>40</td>\n",
       "      <td>Tue May  1 09:11:54 2018</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>0.8918</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 11:47:49 2018</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:09:15 2018</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:23:36 2018</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:23:36 2018</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0.8762</td>\n",
       "      <td>645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:23:36 2018</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:48:35 2018</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:48:35 2018</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      node  cuda  multi_gpu  batch_size  train_epochs  \\\n",
       "4   wolfgangs-mac-pro.home     0          0          64            10   \n",
       "5                   MacPro     0          0         256             4   \n",
       "6                    PC-16     1          1         256            40   \n",
       "7   wolfgangs-mac-pro.home     0          0         256             4   \n",
       "8   wolfgangs-mac-pro.home     0          0         256             4   \n",
       "9   wolfgangs-mac-pro.home     0          0         256             4   \n",
       "10  wolfgangs-mac-pro.home     0          0         256             4   \n",
       "11  wolfgangs-mac-pro.home     0          0         256             4   \n",
       "12  wolfgangs-mac-pro.home     0          0         256             4   \n",
       "13  wolfgangs-mac-pro.home     0          0         256             4   \n",
       "\n",
       "                   localtime   steps  accuracy  duration  \n",
       "4   Mon Apr 30 17:28:43 2018     NaN       NaN       NaN  \n",
       "5   Tue May  1 06:36:35 2018   940.0    0.8801       NaN  \n",
       "6   Tue May  1 09:11:54 2018  9400.0    0.8918       NaN  \n",
       "7   Tue May  1 11:47:49 2018   940.0    0.8770       NaN  \n",
       "8   Tue May  1 12:09:15 2018  1880.0    0.8825       NaN  \n",
       "9   Tue May  1 12:23:36 2018   940.0    0.8681     290.0  \n",
       "10  Tue May  1 12:23:36 2018  1880.0    0.8762     645.0  \n",
       "11  Tue May  1 12:23:36 2018  2820.0    0.8794      13.0  \n",
       "12  Tue May  1 12:48:35 2018   940.0    0.8756      12.0  \n",
       "13  Tue May  1 12:48:35 2018  1880.0    0.8860      12.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIST_FILE_NAME = 'experiment_history.csv'\n",
    "history = ExpHistory(HIST_FILE_NAME)\n",
    "\n",
    "localtime = time.asctime(time.localtime(time.time()))\n",
    "user = os.environ.get('USER', os.environ.get('USERNAME', 'anonymous'))\n",
    "print(\"\\n\\n\")\n",
    "print(\"Welcome, %s, it's %s, and you'll be working with Tensorflow version %s\" % (user, localtime, tf.__version__))\n",
    "rt=os_info()\n",
    "this_os = rt['os']\n",
    "this_node = rt['node']\n",
    "this_machine = rt['machine']\n",
    "this_cuda = rt['cuda']\n",
    "print(\"Your current runtime: \\n  node: %s, \\n  os: %s, \\n  machine: %s, \\n  cuda: %s\" % (this_node, this_os, this_machine, this_cuda))\n",
    "print(\"\\n\")\n",
    "columns=[\n",
    "    'node', \n",
    "    #'os',\n",
    "    #'machine',\n",
    "    'cuda',\n",
    "    'multi_gpu',\n",
    "    'batch_size',\n",
    "    #'data_dir',\n",
    "    #'model_dir',\n",
    "    'train_epochs',\n",
    "    #'user',\n",
    "    #'time_stamp',\n",
    "    'localtime',\n",
    "    'steps',\n",
    "    'accuracy',\n",
    "    'duration'\n",
    "]\n",
    "#history.experiments.tail(10)\n",
    "\n",
    "history.experiments.tail(10)[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to start with the most recent record from this platform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node                                                       scylla\n",
       "os              Linux-4.13.0-39-generic-x86_64-with-Ubuntu-16....\n",
       "machine                                                    x86_64\n",
       "cuda                                                         True\n",
       "multi_gpu                                                       0\n",
       "batch_size                                                    256\n",
       "data_dir                            /var/ellie/data/mnist_fashion\n",
       "model_dir                                        /tmp/mnist_model\n",
       "train_epochs                                                    4\n",
       "user                                                    wgiersche\n",
       "timestamp                                              1525172006\n",
       "localtime                                Tue May  1 12:53:26 2018\n",
       "accuracy                                                    0.886\n",
       "steps                                                        1880\n",
       "duration                                                       12\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams=history.last_experiment_from_here()\n",
    "#hparams=history.copy_from_record(2)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use as new hyper-parameter record, with adaptations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node                                                       scylla\n",
       "os              Linux-4.13.0-39-generic-x86_64-with-Ubuntu-16....\n",
       "machine                                                    x86_64\n",
       "cuda                                                         True\n",
       "multi_gpu                                                   False\n",
       "batch_size                                                    256\n",
       "data_dir                            /var/ellie/data/mnist_fashion\n",
       "model_dir                                        /tmp/mnist_model\n",
       "train_epochs                                                    4\n",
       "user                                                    wgiersche\n",
       "timestamp                                              1525172006\n",
       "localtime                                Tue May  1 12:53:26 2018\n",
       "accuracy                                                    0.886\n",
       "steps                                                        1880\n",
       "duration                                                       12\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.train_epochs = 4\n",
    "hparams.batch_size = 256\n",
    "hparams.multi_gpu = False\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of this tutorial, we always start from scratch\n",
    "!rm -rf /tmp/mnist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_function = create_model_fn(\n",
    "    lambda params: Model(params),\n",
    "    tf.train.AdamOptimizer(),\n",
    "    hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = ('channels_first' if tf.test.is_built_with_cuda() else 'channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f89672fb0d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/mnist_model', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_function,\n",
    "    model_dir=hparams.model_dir,\n",
    "    params={\n",
    "        'data_format': data_format,\n",
    "        'multi_gpu': hparams.multi_gpu\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```input_fn``` functions are a factories for ```DataSet```s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    ds = dataset.training_dataset(hparams.data_dir)\n",
    "    ds = ds.cache().shuffle(buffer_size=50000).\\\n",
    "        batch(hparams.batch_size).\\\n",
    "        repeat(hparams.train_epochs)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn():\n",
    "    return dataset.test_dataset(hparams.data_dir).\\\n",
    "        batch(hparams.batch_size).\\\n",
    "        make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_to_log = {'train_accuracy': 'train_accuracy'}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training and report the new hyper-parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_model/model.ckpt-940\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 941 into /tmp/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:train_accuracy = 0.9140625\n",
      "INFO:tensorflow:loss = 0.22301891, step = 940\n",
      "INFO:tensorflow:global_step/sec: 149.807\n",
      "INFO:tensorflow:loss = 0.2654615, step = 1040 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.354\n",
      "INFO:tensorflow:loss = 0.24799642, step = 1140 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.406\n",
      "INFO:tensorflow:loss = 0.28721142, step = 1240 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.779\n",
      "INFO:tensorflow:loss = 0.22506666, step = 1340 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.378\n",
      "INFO:tensorflow:loss = 0.2845953, step = 1440 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.428\n",
      "INFO:tensorflow:loss = 0.28078112, step = 1540 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.129\n",
      "INFO:tensorflow:loss = 0.22633934, step = 1640 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.631\n",
      "INFO:tensorflow:loss = 0.2107129, step = 1740 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 560.378\n",
      "INFO:tensorflow:loss = 0.23877844, step = 1840 (0.179 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1880 into /tmp/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.29149806.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-01-10:54:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_model/model.ckpt-1880\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-01-10:54:08\n",
      "INFO:tensorflow:Saving dict for global step 1880: accuracy = 0.8841, global_step = 1880, loss = 0.31890506\n",
      "Evaluation results:\n",
      "\t{'loss': 0.31890506, 'global_step': 1880, 'accuracy': 0.8841}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "node                                                       scylla\n",
       "os              Linux-4.13.0-39-generic-x86_64-with-Ubuntu-16....\n",
       "machine                                                    x86_64\n",
       "cuda                                                         True\n",
       "multi_gpu                                                   False\n",
       "batch_size                                                    256\n",
       "data_dir                            /var/ellie/data/mnist_fashion\n",
       "model_dir                                        /tmp/mnist_model\n",
       "train_epochs                                                    4\n",
       "user                                                    wgiersche\n",
       "timestamp                                              1525172006\n",
       "localtime                                Tue May  1 12:53:26 2018\n",
       "accuracy                                                   0.8841\n",
       "steps                                                        1880\n",
       "duration                                                        4\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "start_time=time.time()\n",
    "mnist_classifier.train(input_fn=train_input_fn, hooks=[logging_hook])\n",
    "duration=time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "hparams.accuracy = eval_results['accuracy']\n",
    "hparams.steps = eval_results['global_step']\n",
    "hparams.duration = int(duration)\n",
    "\n",
    "# Report!\n",
    "history.report_experiment(hparams)\n",
    "\n",
    "print('Evaluation results:\\n\\t%s' % eval_results)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
