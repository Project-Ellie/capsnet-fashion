{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import dataset\n",
    "# from models.conv2_dense2_dropout import Model\n",
    "from models.dense3 import Model\n",
    "\n",
    "from helpers.history import history\n",
    "from helpers.gpu_utils import validate_batch_size_for_multi_gpu\n",
    "from helpers.softmax_cross_entropy_trainer import create_model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the history and the runtime context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Welcome, wgi, it's Mon Apr 30 13:49:32 2018, and you'll be working with Tensorflow version 1.8.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>data_dir</th>\n",
       "      <th>model_dir</th>\n",
       "      <th>multi_gpu</th>\n",
       "      <th>train_epochs</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>localtime</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>/tmp/mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>wgiersche</td>\n",
       "      <td>1.525010e+09</td>\n",
       "      <td>Sun Apr 29 15:50:38 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>/tmp/mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>wgiersche</td>\n",
       "      <td>1.525010e+09</td>\n",
       "      <td>Sun Apr 29 15:50:38 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>/tmp/mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>wgiersche</td>\n",
       "      <td>1.525012e+09</td>\n",
       "      <td>Sun Apr 29 16:24:48 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>/tmp/mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>wgiersche</td>\n",
       "      <td>1.525012e+09</td>\n",
       "      <td>Sun Apr 29 16:33:03 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>/tmp/mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>wgiersche</td>\n",
       "      <td>1.525017e+09</td>\n",
       "      <td>Sun Apr 29 17:50:42 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>/tmp/mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>wgiersche</td>\n",
       "      <td>1.525017e+09</td>\n",
       "      <td>Sun Apr 29 17:50:42 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>/tmp/mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>wgiersche</td>\n",
       "      <td>1.525018e+09</td>\n",
       "      <td>Sun Apr 29 18:05:46 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>/var/ellie/data/mnist_fashion</td>\n",
       "      <td>C:\\tmp\\mnist_model</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>wgi</td>\n",
       "      <td>1.525089e+09</td>\n",
       "      <td>Mon Apr 30 13:48:20 2018</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>1410.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size                       data_dir           model_dir  multi_gpu  \\\n",
       "0         128  /var/ellie/data/mnist_fashion    /tmp/mnist_model      False   \n",
       "1         128  /var/ellie/data/mnist_fashion    /tmp/mnist_model      False   \n",
       "2          64  /var/ellie/data/mnist_fashion    /tmp/mnist_model      False   \n",
       "3          64  /var/ellie/data/mnist_fashion    /tmp/mnist_model      False   \n",
       "4          64  /var/ellie/data/mnist_fashion    /tmp/mnist_model      False   \n",
       "5          64  /var/ellie/data/mnist_fashion    /tmp/mnist_model      False   \n",
       "6          64  /var/ellie/data/mnist_fashion    /tmp/mnist_model      False   \n",
       "7         256  /var/ellie/data/mnist_fashion  C:\\tmp\\mnist_model      False   \n",
       "\n",
       "   train_epochs       user     timestamp                 localtime  accuracy  \\\n",
       "0            10  wgiersche  1.525010e+09  Sun Apr 29 15:50:38 2018       NaN   \n",
       "1            10  wgiersche  1.525010e+09  Sun Apr 29 15:50:38 2018       NaN   \n",
       "2             5  wgiersche  1.525012e+09  Sun Apr 29 16:24:48 2018       NaN   \n",
       "3            10  wgiersche  1.525012e+09  Sun Apr 29 16:33:03 2018       NaN   \n",
       "4            10  wgiersche  1.525017e+09  Sun Apr 29 17:50:42 2018       NaN   \n",
       "5            10  wgiersche  1.525017e+09  Sun Apr 29 17:50:42 2018       NaN   \n",
       "6            10  wgiersche  1.525018e+09  Sun Apr 29 18:05:46 2018       NaN   \n",
       "7             6        wgi  1.525089e+09  Mon Apr 30 13:48:20 2018    0.9801   \n",
       "\n",
       "    steps  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "5     NaN  \n",
       "6     NaN  \n",
       "7  1410.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localtime = time.asctime(time.localtime(time.time()))\n",
    "user = os.environ['USERNAME']\n",
    "print(\"\\n\\n\")\n",
    "print(\"Welcome, %s, it's %s, and you'll be working with Tensorflow version %s\" % (user, localtime, tf.__version__))\n",
    "print(\"\\n\")\n",
    "history.experiments.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new hyper-parameter record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/var/ellie/data/mnist_fashion': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /var/ellie/data/mnist_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_size                                256\n",
       "data_dir        /var/ellie/data/mnist_fashion\n",
       "model_dir                  C:\\tmp\\mnist_model\n",
       "multi_gpu                               False\n",
       "train_epochs                                6\n",
       "user                                      wgi\n",
       "timestamp                         1.52509e+09\n",
       "localtime            Mon Apr 30 13:48:20 2018\n",
       "accuracy                                  NaN\n",
       "steps                                     NaN\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new hyper-parameter record from a history entry\n",
    "FLAGS = history.copy_from_record(2)\n",
    "\n",
    "# Choose new parameters\n",
    "FLAGS.train_epochs = 6\n",
    "FLAGS.batch_size = 256\n",
    "FLAGS.model_dir='C:\\\\tmp\\\\mnist_model'\n",
    "FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of this tutorial, we always start from scratch\n",
    "!rm -rf C:\\tmp\\mnist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_function = create_model_fn(\n",
    "    lambda params: Model(params), \n",
    "    tf.train.AdamOptimizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAGS.multi_gpu:\n",
    "    validate_batch_size_for_multi_gpu(FLAGS.batch_size)\n",
    "\n",
    "    # There are two steps required if using multi-GPU: (1) wrap the model_fn,\n",
    "    # and (2) wrap the optimizer. The first happens here, and (2) happens\n",
    "    # in the model_fn itself when the optimizer is defined.\n",
    "    model_function = tf.contrib.estimator.replicate_model_fn(\n",
    "        model_function, loss_reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "data_format = ('channels_first' if tf.test.is_built_with_cuda() else 'channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\tmp\\\\mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000024D529EE6A0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_function,\n",
    "    model_dir=FLAGS.model_dir,\n",
    "    params={\n",
    "        'data_format': data_format,\n",
    "        'multi_gpu': FLAGS.multi_gpu\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```input_fn``` functions are a factories for ```DataSet```s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    ds = dataset.training_dataset(FLAGS.data_dir)\n",
    "    ds = ds.cache().shuffle(buffer_size=50000).\\\n",
    "        batch(FLAGS.batch_size).\\\n",
    "        repeat(FLAGS.train_epochs)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn():\n",
    "    return dataset.test_dataset(FLAGS.data_dir).batch(\n",
    "        FLAGS.batch_size).make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_to_log = {'train_accuracy': 'train_accuracy'}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training and report the new experiment's hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\tmp\\mnist_model\\model.ckpt.\n",
      "INFO:tensorflow:train_accuracy = 0.09375\n",
      "INFO:tensorflow:loss = 2.3211517, step = 1\n",
      "INFO:tensorflow:global_step/sec: 64.3006\n",
      "INFO:tensorflow:loss = 0.16576661, step = 101 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4761\n",
      "INFO:tensorflow:loss = 0.12136151, step = 201 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7191\n",
      "INFO:tensorflow:loss = 0.07683261, step = 301 (1.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.49\n",
      "INFO:tensorflow:loss = 0.06109284, step = 401 (1.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.4091\n",
      "INFO:tensorflow:loss = 0.043292683, step = 501 (1.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7338\n",
      "INFO:tensorflow:loss = 0.027377024, step = 601 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4422\n",
      "INFO:tensorflow:loss = 0.089909665, step = 701 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.6601\n",
      "INFO:tensorflow:loss = 0.04134415, step = 801 (1.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4785\n",
      "INFO:tensorflow:loss = 0.0120548, step = 901 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1293\n",
      "INFO:tensorflow:train_accuracy = 0.9009233 (12.865 sec)\n",
      "INFO:tensorflow:loss = 0.00717628, step = 1001 (1.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5593\n",
      "INFO:tensorflow:loss = 0.052619368, step = 1101 (1.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9715\n",
      "INFO:tensorflow:loss = 0.018363386, step = 1201 (1.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.3082\n",
      "INFO:tensorflow:loss = 0.013166281, step = 1301 (1.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2865\n",
      "INFO:tensorflow:loss = 0.028122835, step = 1401 (1.247 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1410 into C:\\tmp\\mnist_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.066993654.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-30-11:49:01\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\tmp\\mnist_model\\model.ckpt-1410\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-30-11:49:02\n",
      "INFO:tensorflow:Saving dict for global step 1410: accuracy = 0.9801, global_step = 1410, loss = 0.064816944\n",
      "Evaluation results:\n",
      "\t{'accuracy': 0.9801, 'loss': 0.064816944, 'global_step': 1410}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "batch_size                                256\n",
       "data_dir        /var/ellie/data/mnist_fashion\n",
       "model_dir                  C:\\tmp\\mnist_model\n",
       "multi_gpu                               False\n",
       "train_epochs                                6\n",
       "user                                      wgi\n",
       "timestamp                         1.52509e+09\n",
       "localtime            Mon Apr 30 13:48:20 2018\n",
       "accuracy                               0.9801\n",
       "steps                                    1410\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "mnist_classifier.train(input_fn=train_input_fn, hooks=[logging_hook])\n",
    "# evaluate \n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "# report\n",
    "FLAGS.accuracy = eval_results['accuracy']\n",
    "FLAGS.steps = eval_results['global_step']\n",
    "history.report_experiment(FLAGS)\n",
    "\n",
    "print('Evaluation results:\\n\\t%s' % eval_results)\n",
    "FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
