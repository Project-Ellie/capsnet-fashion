{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import dataset\n",
    "# from models.conv2_dense2_dropout import Model\n",
    "from models.dense3 import Model\n",
    "\n",
    "from helpers.os_utils import os_info\n",
    "from helpers.history import ExpHistory\n",
    "#from helpers.gpu_utils import validate_batch_size_for_multi_gpu\n",
    "from helpers.softmax_cross_entropy_trainer import create_model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the history and the runtime context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Welcome, wgiersche, it's Tue May  1 12:37:02 2018, and you'll be working with Tensorflow version 1.8.0\n",
      "Your current runtime: \n",
      "  node: wolfgangs-mac-pro.home, \n",
      "  os: Darwin-15.6.0-x86_64-i386-64bit, \n",
      "  machine: x86_64, \n",
      "  cuda: False\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>cuda</th>\n",
       "      <th>multi_gpu</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_epochs</th>\n",
       "      <th>localtime</th>\n",
       "      <th>steps</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZRHN1979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon Apr 30 13:48:20 2018</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MacPro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon Apr 30 17:28:43 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon Apr 30 17:28:43 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MacPro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 06:36:35 2018</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PC-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>40</td>\n",
       "      <td>Tue May  1 09:11:54 2018</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>0.8918</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 11:47:49 2018</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:09:15 2018</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:23:36 2018</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:23:36 2018</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0.8762</td>\n",
       "      <td>645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wolfgangs-mac-pro.home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue May  1 12:23:36 2018</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      node  cuda  multi_gpu  batch_size  train_epochs  \\\n",
       "2                 ZRHN1979     0          0         256             6   \n",
       "3                   MacPro     0          0          64            10   \n",
       "4   wolfgangs-mac-pro.home     0          0          64            10   \n",
       "5                   MacPro     0          0         256             4   \n",
       "6                    PC-16     1          1         256            40   \n",
       "7   wolfgangs-mac-pro.home     0          0         256             4   \n",
       "8   wolfgangs-mac-pro.home     0          0         256             4   \n",
       "9   wolfgangs-mac-pro.home     0          0         256             4   \n",
       "10  wolfgangs-mac-pro.home     0          0         256             4   \n",
       "11  wolfgangs-mac-pro.home     0          0         256             4   \n",
       "\n",
       "                   localtime   steps  accuracy  duration  \n",
       "2   Mon Apr 30 13:48:20 2018  1410.0    0.9801       NaN  \n",
       "3   Mon Apr 30 17:28:43 2018     NaN       NaN       NaN  \n",
       "4   Mon Apr 30 17:28:43 2018     NaN       NaN       NaN  \n",
       "5   Tue May  1 06:36:35 2018   940.0    0.8801       NaN  \n",
       "6   Tue May  1 09:11:54 2018  9400.0    0.8918       NaN  \n",
       "7   Tue May  1 11:47:49 2018   940.0    0.8770       NaN  \n",
       "8   Tue May  1 12:09:15 2018  1880.0    0.8825       NaN  \n",
       "9   Tue May  1 12:23:36 2018   940.0    0.8681     290.0  \n",
       "10  Tue May  1 12:23:36 2018  1880.0    0.8762     645.0  \n",
       "11  Tue May  1 12:23:36 2018  2820.0    0.8794      13.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIST_FILE_NAME = 'experiment_history.csv'\n",
    "history = ExpHistory(HIST_FILE_NAME)\n",
    "\n",
    "localtime = time.asctime(time.localtime(time.time()))\n",
    "user = os.environ.get('USER', os.environ.get('USERNAME', 'anonymous'))\n",
    "print(\"\\n\\n\")\n",
    "print(\"Welcome, %s, it's %s, and you'll be working with Tensorflow version %s\" % (user, localtime, tf.__version__))\n",
    "rt=os_info()\n",
    "this_os = rt['os']\n",
    "this_node = rt['node']\n",
    "this_machine = rt['machine']\n",
    "this_cuda = rt['cuda']\n",
    "print(\"Your current runtime: \\n  node: %s, \\n  os: %s, \\n  machine: %s, \\n  cuda: %s\" % (this_node, this_os, this_machine, this_cuda))\n",
    "print(\"\\n\")\n",
    "columns=[\n",
    "    'node', \n",
    "    #'os',\n",
    "    #'machine',\n",
    "    'cuda',\n",
    "    'multi_gpu',\n",
    "    'batch_size',\n",
    "    #'data_dir',\n",
    "    #'model_dir',\n",
    "    'train_epochs',\n",
    "    #'user',\n",
    "    #'time_stamp',\n",
    "    'localtime',\n",
    "    'steps',\n",
    "    'accuracy',\n",
    "    'duration'\n",
    "]\n",
    "#history.experiments.tail(10)\n",
    "\n",
    "history.experiments.tail(10)[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to start with the most recent record from this platform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node                     wolfgangs-mac-pro.home\n",
       "os              Darwin-15.6.0-x86_64-i386-64bit\n",
       "machine                                  x86_64\n",
       "cuda                                      False\n",
       "multi_gpu                                     0\n",
       "batch_size                                  256\n",
       "data_dir          /var/ellie/data/mnist_fashion\n",
       "model_dir                      /tmp/mnist_model\n",
       "train_epochs                                  4\n",
       "user                                  wgiersche\n",
       "timestamp                           1.52517e+09\n",
       "localtime              Tue May  1 12:23:36 2018\n",
       "accuracy                                 0.8825\n",
       "steps                                      1880\n",
       "duration                                    NaN\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams=history.last_experiment_from_here()\n",
    "#hparams=history.copy_from_record(2)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use as new hyper-parameter record, with adaptations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node                     wolfgangs-mac-pro.home\n",
       "os              Darwin-15.6.0-x86_64-i386-64bit\n",
       "machine                                  x86_64\n",
       "cuda                                      False\n",
       "multi_gpu                                 False\n",
       "batch_size                                  256\n",
       "data_dir          /var/ellie/data/mnist_fashion\n",
       "model_dir                      /tmp/mnist_model\n",
       "train_epochs                                  4\n",
       "user                                  wgiersche\n",
       "timestamp                           1.52517e+09\n",
       "localtime              Tue May  1 12:23:36 2018\n",
       "accuracy                                 0.8825\n",
       "steps                                      1880\n",
       "duration                                    NaN\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.train_epochs = 4\n",
    "hparams.batch_size = 256\n",
    "hparams.multi_gpu = False\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of this tutorial, we always start from scratch\n",
    "!rm -rf /tmp/mnist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_function = create_model_fn(\n",
    "    lambda params: Model(params),\n",
    "    tf.train.AdamOptimizer(),\n",
    "    hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = ('channels_first' if tf.test.is_built_with_cuda() else 'channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1203f8588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_function,\n",
    "    model_dir=FLAGS.model_dir,\n",
    "    params={\n",
    "        'data_format': data_format,\n",
    "        'multi_gpu': hparams.multi_gpu\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```input_fn``` functions are a factories for ```DataSet```s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    ds = dataset.training_dataset(hparams.data_dir)\n",
    "    ds = ds.cache().shuffle(buffer_size=50000).\\\n",
    "        batch(hparams.batch_size).\\\n",
    "        repeat(hparams.train_epochs)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn():\n",
    "    return dataset.test_dataset(hparams.data_dir).\\\n",
    "        batch(hparams.batch_size).\\\n",
    "        make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_to_log = {'train_accuracy': 'train_accuracy'}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training and report the new hyper-parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_model/model.ckpt-1880\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1881 into /tmp/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:train_accuracy = 0.90234375\n",
      "INFO:tensorflow:loss = 0.21433017, step = 1881\n",
      "INFO:tensorflow:global_step/sec: 64.6558\n",
      "INFO:tensorflow:loss = 0.21454248, step = 1981 (1.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.928\n",
      "INFO:tensorflow:loss = 0.1990244, step = 2081 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.903\n",
      "INFO:tensorflow:loss = 0.2306441, step = 2181 (0.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.113\n",
      "INFO:tensorflow:loss = 0.18670043, step = 2281 (0.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.807\n",
      "INFO:tensorflow:loss = 0.17812634, step = 2381 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.863\n",
      "INFO:tensorflow:loss = 0.17520937, step = 2481 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.663\n",
      "INFO:tensorflow:loss = 0.22279567, step = 2581 (0.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.806\n",
      "INFO:tensorflow:loss = 0.26567018, step = 2681 (0.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.915\n",
      "INFO:tensorflow:loss = 0.18665954, step = 2781 (0.863 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2820 into /tmp/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1877312.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-01-10:32:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_model/model.ckpt-2820\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-01-10:33:00\n",
      "INFO:tensorflow:Saving dict for global step 2820: accuracy = 0.8794, global_step = 2820, loss = 0.34842914\n",
      "Evaluation results:\n",
      "\t{'accuracy': 0.8794, 'loss': 0.34842914, 'global_step': 2820}\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "start_time=time.time()\n",
    "mnist_classifier.train(input_fn=train_input_fn, hooks=[logging_hook])\n",
    "duration=time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "hparams.accuracy = eval_results['accuracy']\n",
    "hparams.steps = eval_results['global_step']\n",
    "hparams.duration = int(duration)\n",
    "\n",
    "# Report!\n",
    "history.report_experiment(hparams)\n",
    "\n",
    "print('Evaluation results:\\n\\t%s' % eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node                     wolfgangs-mac-pro.home\n",
       "os              Darwin-15.6.0-x86_64-i386-64bit\n",
       "machine                                  x86_64\n",
       "cuda                                      False\n",
       "multi_gpu                                 False\n",
       "batch_size                                  256\n",
       "data_dir          /var/ellie/data/mnist_fashion\n",
       "model_dir                      /tmp/mnist_model\n",
       "train_epochs                                  4\n",
       "user                                  wgiersche\n",
       "timestamp                           1.52517e+09\n",
       "localtime              Tue May  1 12:23:36 2018\n",
       "accuracy                                 0.8681\n",
       "steps                                       940\n",
       "duration                                290.186\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(hparams.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
